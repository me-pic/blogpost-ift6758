---
layout: post
title: Milestone 2
---

## Résumé

La deuxième partie de ce projet s'est concentrée sur l'ingénierie des caractéristiques (*feature engineering*) et le développement de modèles permettant de prédire les buts espérés (*expected Goals*; xG).

## Aperçu des données

Cette section fournie une description des données qui ont été utilisés dans cette étape du projet.

Les données utilisées proviennent de l'API de la LNH. Les données jeu-par-jeu (*play-by-play*) des saisons 2016-2017 à 2020-2021 inclusivement. Plus précisément, les données des saisons régulières de 2016-2017 jusqu'à 2019-2020 inclusivement ont été utilisées pour entraîner et valider les modèles développés. Toutes les données de la saison 2020-2021 ont été utilisées pour tester les modèles.

## Ingénérie des caractéristiques I

Les figures de la section ci-dessous peuvent être générées en roulant les cellules de la section Milestone 2 dans le notebook [visualisation.ipynb](https://github.com/mathieupelo/ift6758-A08/blob/main/notebooks/visualisation.ipynb). Cette section explore le nombre de tirs (buts vs non-buts) en fonction de la distance et l'angle entre le tireur et le filet. Pour calculer ces variables, nous avons pris en compte le point milieu du filet, soit les coordonnées absolues (89, 0).

La distance euclédienne entre le tir et le filet a été calculée de la manière suivante:
```
distance = np.sqrt((x_filet - np.abs(x_tir))**2 + (y_filet - np.abs(y_tir))**2)
```

L'angle entre le tir et le filet a été calculé comme suit:
```
angle = np.arctan((y_filet - y_tir)/(x_filet - np.abs(x_tir)))
```
Puis converti en degré:
```
angle = np.rad2deg(angle)
```

Les calculs de l'angle et de la distance ont été implémentés dans le script feature_engineering.py avec la librairie [numpy](https://numpy.org/doc/stable/).

### Question 1

Visuellement, nous pouvons observer que le nombre de tirs selon la distance ne semble pas être distribué normalement, autant pour les buts que les non-buts (voir Figure ci-dessous; gauche: données non-transformées, droite: données log transformées). En effet, la majorité des tirs (buts et non-buts) sont effectués à environ 10 pieds du filet. Au-delà de 10 pieds, le nombre de non-buts diminue et reste relativement stable entre 20 et 60 pieds pour diminuer de manière drastique au-delà de 60 pieds du filet. Le nombre de buts semble diminué de manière constante entre 20 et 60 pieds. au-delà de 60 pieds, le nombre de buts semble suivre la même tendance que le nombre de non-buts. Nous pouvons également conclure qu'il y a beaucoup moins de buts que de non-buts.

<p align="center">
      <img src="../assets/images/milestone2/shots_goals_distance.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/shots_goals_distance_log.png" width="550" height="425">
</p>

Le nombre de tirs selon l'angle n'est pas distribué normalement, autant pour les buts que les non-buts. Nous pouvons observer que la distribution des non-buts semble être tri-modale, avec un pic à environ -30 degrés, un pic à 0 degré et un pic à environ 30 degré. La distribution de part et d'autres du zéro semble assez symétrique, ce qui suggère que nous pourrions considérer la valeur absolue des angles. En d'autres mots, que le tireur soit à gauche ou à droite du gradien ne semble pas avoir d'incidence sur le nombre de tirs ainsi que sur le nombre de buts. La distribution des buts ressemble un peu plus à une distribution normale, bien qu'il y a une prévalence qu'il y a un nombre de buts plus important lorsque l'angle entre le tireur et le filet est proche de 0.

<p align="center">
      <img src="../assets/images/milestone2/shots_goals_angle.png" align="left" width="550" height="425">
      <img src="../assets/images/milestone2/shots_goals_angle_log.png" width="550" height="425">
</p>

Nous pouvons tirer les mêmes conclusions globales que précédemment en regardant l'histogramme 2D ci-dessous. Par contre, il est à noter que les tirs ne sont pas séparés en buts et  non-buts dans cette figure. L'histogramme 2D nous permet également de voir qu'à plus de 40 pieds du filet, l'angle de tir décroit de manière exponentielle jusqu'à environ 25 degrés. 

<img src="../assets/images/milestone2/hist_2d_distance_angle.png">


### Question 2

Le taux de buts décroit à mesure que la distance augmente entre le tir et le filet augmenter (Figure de gauche). Ce taux est plus grand lorsque l'angle entre le tir et le filet est environ entre 5 et 10 degrés. Par la suite, le taux de buts diminue plus l'angle augmente.

<p align="center">
    <img src="../assets/images/milestone2/goal_rate_distance.png" align="left" height="400" width="590">
    <img src="../assets/images/milestone2/goal_rate_angle.png" height="400" width="590">
</p>

### Question 3

Nous pouvons observer qu'il y a un plus grand nombre de buts marqués aux alentours de 10 pieds lorsque le filet n'est pas vide. Lorsque la distance entre le tir et le filet dépasse les 10 pieds, le nombre de buts marqués diminue presque exponentiellement en fonction de la distance. Lorsque le filet est vide, le nombre de buts ne semble pas dépendre de la distance entre le tir et le filet.

<p align="center">
      <img src="../assets/images/milestone2/goals_distance_empty_goal.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/goals_distance_empty_goal_log.png" width="550" height="425">
</p>


## Modèles de base

Le premier modèle demandé se base sur la distance entre le tir et le filet pour prédire les buts espérés. Il a été entraîné sur 80% des données et la précision (*accuracy*) a été calculée sur le 20% des données restantes. Nous avons obtenu une précision de 90.62 %. La métrique de précision (*accuracy*) ne tient malheureusement pas compte des prédictions faites par classe, uniquement des prédictions sur l'ensemble des classes. Ceci pose un problème lorsque nous avons des classes débalancées. En effet, si l'on regarde la proportion de chaque classe dans nos données, nous pouvons observer que 90.62% de nos observations appartiennent à la classe 0 (i.e., non-but). En regardant la matrice de confusion, nous pouvons bel et bien voir que ce modèle prédit systématiquement la classe majoritaire.
```
[[55426     0]
[ 5734      0]]

où les lignes correspondes aux vrais classes (0, 1) et les colonnes correspondes aux classes prédites (0,1)
Nombre de vrais négatifs = 55426, nombre de faux négatifs = 5734, nombre de vrais négatifs = 0, nombre de faux négatifs = 0.
```
Ces observations montrent qu'il est donc important de considérer des métriques différentes pour évaluer de manière adéquate nos modèles. Pour les sections suivantes, nous avons donc intégrer la métrique *Area Under the Curve (AUC)* calculée sur les courbes *Receiver Operating Characteristic (ROC)* évalué sur le modèle précédent. Deux nouveaux modèles de régression logistique ont été entraînées. Un incluant uniquement l'angle entre le tir et le filet pour prédire les buts espérés, et  l'autre incluant la distance et l'angle entre le tir et le filter pour réaliser cette prédiction. Ces modèles ont été entraînés sur 80% des données d'entraînement et évaluer sur les 20% restants.

<p align="center">
      <img src="../assets/images/milestone2/ROC_curves_basic_models.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/Centiles_plot_basic_models.png" width="560" height="425">
</p>
<p align="center">
      <img src="../assets/images/milestone2/cumulative_centiles_plot_basic_models.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/calibrate_display_basic_models.png" width="550" height="425">
</p>

Les figures nous permettent d'observer que la courbe ROC du modèle basé uniquement sur la distance de tir se situe au-dessus du niveau de chance. L'angle de tir ne semble apporter aucune information pertinente pour prédire si un tir va résulter en un but ou non. En effet, les performances du modèle inclunat uniquement l'angle de tir oscillent autour de la change. De plus, le modèle basé sur la distance et celui basé sur la distance et l'angle de tir ont des courbes qui se superposent, suggérant l'apport inexistant de la variable angle de tir sur la prédiction des buts espérés.

Le code pour produire les graphiques demandés se trouve dans le script [`Plots.py`](https://github.com/mathieupelo/ift6758-A08/blob/main/scripts/Plots.py). Ce code a été réutilisé dans les sections suivantes.

## Ingénierie des caractéristiques II

Ci-dessous se trouve la liste des caractéristiques créées:

- `prd`: indique la période du match (1, 2, 3, prolongation, tirs au but)
- `is_goal`: indique si le tir a résulté en un but
- `shotCategory`: catégorie ou type de tir effectué
- `coord_x`: coordonnée horizontale de l'action sur la glace
- `coord_y`: coordonnée verticale de l'action sur la glace
- `empty_net`: Indique si le but était vide lors du tir
- `last_event_type`: type de la dernière action enregistrée
- `last_event_x`: coordonnée horizontale de la dernière action
- `last_event_y`: coordonnée verticale de la dernière action
- `time_since_last_event`: temps écoulé depuis la dernière action (en secondes)
- `distance_from_last_event`: distance parcourue depuis la dernière action
- `game_seconds`: temps total écoulé dans le match (en secondes)
- `shot_distance`: distance du tir par rapport au but
- `shot_angle`: angle du tir par rapport au but
- `rebond`: indique si le tir était un rebond d'un tir précédent
- `changement_angle_tir`: changement d'angle entre ce tir et le tir précédent
- `vitesse`: vitesse du tir (distance depuis l'évènement précédent / temps depuis l'évènement précédent)
- `power_play_time_elapsed`: temps écoulé depuis le jeu de puissance (secondes)
- `home_team_skater_count`: nombre de joueurs présents sur la glace de l'équipe hôte (sans le gardien de but)
- `away_team_skater_count`: nombre de joueurs présents sur la glace de l'équipe visiteur (sans le gardien de but)

Le code utilisé pour générer le nouveau DataFrame se trouve dans le script [`feature_engineering.py`](https://github.com/mathieupelo/ift6758-A08/blob/main/scripts/feature_engineering.py). Il est possible d'accéder à l'artefact Dataframe via le [lien vers l'expérience Comet](https://www.comet.com/me-pic/milestone-2/0ead41c0bc834bf1a776452bbb08792f).

Les modèles présentés dans les sections suivantes ont tous été entraînés sur les données prétraitées de DataFrame.


> **Prétraitement des caractéristiques:**
> <br>La variable *prdTime* a été enlevée puisqu'elle est redondante avec les variables *prd* et *game_seconds* qui ont été incluses dans l'ensemble de caractéristiques. Ensuite, les variables *shotCategory* et *last_event_type* catégorielles ont été encodées avec la technique de *Hot-One-Encoding* selon l'implémentation de la librairie pandas (voir [get_dummies](https://pandas.
pydata.org/docs/reference/api/pandas.get_dummies.html)). Les variables continues *coord_x*, *coord_y*, *last_event_x*, *last_event_y*, *time_since_last_event*, *distance_from_last_event*, *game_seconds*, 
*shot_distance*, *shot_angle*, *changement_angle_tir*, *vitesse*, *power_play_time_elapsed*, *home_team_skater_count* et *away_team_skater_count* ont été standardisées grâce à la fonction [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de scikit-learn. Un encodage binaire a été effectué sur les variables *empty_net* et *rebond* grâce à la fonction [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) de scikit-learn. La variable cible *goalFlag* a également été binarisée. Le prétraitement des données est réalisé par la fonction `preprocessing` se trouvant dans le script [feature_engineering.py](https://github.com/mathieupelo/ift6758-A08/blob/main/scripts/feature_engineering.py).


## Modèles avancés

### Question 1

<p align="center">
      <img src="../assets/images/milestone2/ROC_curve_XGBoost.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/Centiles_plot_XGBoost.png" width="560" height="425">
</p>
<p align="center">
      <img src="../assets/images/milestone2/cumulative_centiles_plot_XGBoost.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/calibrate_display_XGBoost.png" width="550" height="425">
</p>

TODO: Insérer les 4 figures
TODO: discuter de la configuration train/validation
TODO: Insérer lien vers comet.ml
[lien de l'expérience](https://www.comet.com/me-pic/milestone-2/6ba2ea6b31524578bf269752e2ca30dd) sur Comet.

### Question 2

L'optimisation d'hyperparamètres a été effectué en utilisant une approche de recherche par grille (i.e., [*GridSearch*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)). Pour ce modèle, nous avons considéré les trois hyperparamètres ci-dessous, puisqu'ils ont un énorme impact sur la performance du modèle XGBoost. C'est également une pratique commune d'optimiser ces 3 hyperparamètres: 

- `n_estimator`: nombre total d'arbres 
- `max_depth`: profondeur maximale de chaque arbre
- `learning_rate`: taux d'apprentissage utilisé pour mettre à jour la contribution des nouveaux arbres au modèle

La grille de recherche pour ces paramètres a été définie avec les valeurs suivantes:
- `n_estimator`: [50, 100, 200]
- `max_depth`: [3, 5, 7]
- `learning_rate`: [0.01, 0.1, 0.2]

Pour la validation-croisée, un Kfold avec k=5 a été effectué, ce qui signifie que 135 (3x3x3x5) combinaisons possibles d'hyperparamètres ont été testées. La meilleure solution a été trouvée avec les valeurs suivantes:
- `n_estimators` = 200
- `max_depth` = 5
- `learning_rate` = 0.1

Le nouveau modèle entraîné avec les meilleurs hyperparamètres a permis d'obtenir de meilleures performances que le modèle précédent. En effet, avec ce modèle, nous obtenons un score ROC de 0.7942. Il pourrait également être intéressant de tester une autre méthode d'optimisation d'hyperparamètres comme l'hypercube latin aléatoire. Cette dernière permet de couvrir de manière plus efficace la distribution d'hyperparamètres. Il serait également possible de considérer d'autres hyperparamètres à optimiser tels que le nombre maximum de feuille (`max_leaves`), le terme de régularisation (p.ex. `reg_alpha`), le poids minimal de l'enfant (`min_child_weight`), etc.

<p align="center">
      <img src="../assets/images/milestone2/ROC_curve_Best XGBoostGridSearch.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/Centiles_plot_Best XGBoostGridSearch.png" width="560" height="425">
</p>
<p align="center">
      <img src="../assets/images/milestone2/cumulative_centiles_plot_BestXGBoostGridSearch.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/calibrate_display_Best XGBoostGridSearch.png" width="550" height="425">
</p>

TODO: Insérer figure pour justifier le choix des hyperparamètres
TODO: Insérer lien comet.ml

Finalement, nous avons procéder à la sélection de caractéristiques en prenant compte des meilleures valeurs d'hyperparamètre. Pour ce faire, nous avons ressorti tous les scores qui dépassaient un seuil du 60e percentile. Treize caractéristiques ont donc été sélectionnées pour développer un nouveau modèle. Nous avons observé que l'entraînement de ce modèle était plus rapide, mais le score ROC a diminué légèrement (score ROC = 0.7893). Le meilleur modèle pour le XGBoost est donc celui qui contient toutes les caractéristiques et qui est entraîner après avoir fait la recherche d'hyperparamètres (score ROC = 0.794).

<p align="center">
      <img src="../assets/images/milestone2/ROC_curve_XGBoostFeatureSelection.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/Centiles_plot_XGBoostFeatureSelection.png" width="560" height="425">
</p>
<p align="center">
      <img src="../assets/images/milestone2/cumulative_centiles_plot_XGBoostFeatureSelection.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/calibrate_display_XGBoostFeatureSelection.png" width="550" height="425">
</p>

TODO: Discuter stratégies de sélection de features
TODO: Insérer des figures pour justifier le choix
TODO: Insérer les 4 figiures
TODO: Insérer le lien comet.ml

## Faites de votre mieux !

Pour cette partie, nous avons tester trois différents modèles pour prédire les buts espérés: Forêt aléatoire, Machine à vecteurs de support, Réseau de neurones. Les particularités de chaque modèle sont décrites ci-dessous:

### Algorithmes de classification

**Forêt aléatoire (Random Forest)**

L'algorithme de forêt aléatoire a été inclus dans les modèles testés en raison de son efficacité démontrée sur les données tabulaires ([Grinztajn et al., 2022](https://
proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Paper-Datasets_and_Benchmarks.pdf)). Notre modèle est basé sur l'implétation [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) de scikit-learn. 

AJOUTER LIEN COMETML

**Histogram-based Gradien Boost Classification Tree**
Le choix de cet algorithme est basé sur l'article de ([Grinztajn et al., 2022](https://proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Paper-Datasets_and_Benchmarks.pdf)) montrant l'efficacité de ce type de modèle pour prédire des données tabulaires contenant des caractéristiques continues et discrètes, bien que les performances rapportées ne dépassaient pas celles de XGBoost. L'implémentation de scikit-learn ([HistGradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html)) a été utilisé pour développer ce modèle. 

L'entraînement du modèle a été effectué sur 80% des données d'entraînement et l'évaluation a été faite sur le 20% restant. Une recherche aléatoire ([RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)) a été performée sur les paramètres suivants: `learning_rate`, `max_iter` et `max_depth`. La précision balancée (*balanced accuracy*) a été utilisée comme méthode de scoring pour tenir compte de la nature débalancée de notre problème de classification.

AJOUTER LIEN COMETML

**Réseau de neurones**

Un réseau de neurones a également été entraîné et évalué dans cette partie. Le réseau de neurones utilisé est composé de cinq couches. Les quatre premières couches sont des couches cachées qui appliquent une transformation linéaire à l'entrée de la couche. Une fonction d'activation ReLu est appliquée à la sortie de chacune de ces couches pour intégrer des non-linéarités dans le modèle. Une technique de régularisation (dropout) est finalement appliquée après chaque fonction d'activation ReLu pour tenter d'éviter le surapprentissage. La cinquième couche est la couche de sortie.

L'entropie croisée binaire avec une perte logits (*Binary Cross Entropy with Logits Loss*) a été choisie comme fonction de perte. Pour tenir compte du débalancement des classes que nous avons dans nos données, un poids a été assigné à la classe positive. Ce poids a été défini comme le ratio nombre de non-buts : nombre de buts. Les hyperparamètres ont été fixés pour simplifier l'implémentation du modèle (taux d'apprentissage = 0.01, momentum = 0.9, nombre d'époques = 500). Finalement, un optimisateur Stochastic Gradient Descent a été utilisé pour calculer le gradient. Le modèle a été entraîné sur 80% des données d'entraînement et évalué sur les 20% restant. À noter que le modèle retourne les prédictions sous forme de probabilités.

AJOUTER LE LIEN COMETML

### Performance des modèles

TODO: Discuter des différentes techniques utilisées
TODO: Insérer les 4 figures

**Comparaisons des modèles**

## Évaluer sur l'ensemble de test

### Question 1

TODO: Insérer les 4 figures.
TODO: Discuter la performance des modèles

### Question 2

TODO: Insérer les 4 figures
TODO: Discuter la performance des modèles