---
layout: post
title: Milestone 2
---

## Résumé

La deuxième partie de ce projet s'est concentrée sur l'ingénierie des caractéristiques (*feature engineering*) et le développement de modèles permettant de prédire les buts espérés (*expected Goals*; xG).

## Aperçu des données

Cette section fournie une description des données qui ont été utilisés dans cette étape du projet.

Les données utilisées proviennent de l'API de la LNH. Les données jeu-par-jeu (*play-by-play*) des saisons 2016-2017 à 2020-2021 inclusivement. Plus précisément, les données des saisons régulières de 2016-2017 jusqu'à 2019-2020 inclusivement ont été utilisées pour entraîner et valider les modèles développés. Toutes les données de la saison 2020-2021 ont été utilisées pour tester les modèles.

## Ingénérie des caractéristiques I

Les figures de la section ci-dessous peuvent être générées en roulant les cellules de la section Milestone 2 dans le notebook [visualisation.ipynb](https://github.com/mathieupelo/ift6758-A08/blob/main/notebooks/visualisation.ipynb). Cette section explore le nombre de tirs (buts vs non-buts) en fonction de la distance et l'angle entre le tireur et le filet. Pour calculer ces variables, nous avons pris en compte le point milieu du filet, soit les coordonnées absolues (89, 0).

La distance euclédienne entre le tir et le filet a été calculée de la manière suivante:
```
distance = np.sqrt((x_filet - np.abs(x_tir))**2 + (y_filet - np.abs(y_tir))**2)
```

L'angle entre le tir et le filet a été calculé comme suit:
```
angle = np.arctan((y_filet - y_tir)/(x_filet - np.abs(x_tir)))
```
Puis converti en degré:
```
angle = np.rad2deg(angle)
```

Les calculs de l'angle et de la distance ont été implémentés dans le script feature_engineering.py avec la librairie [numpy](https://numpy.org/doc/stable/).

### Question 1

Visuellement, nous pouvons observer que le nombre de tirs selon la distance ne semble pas être distribué normalement, autant pour les buts que les non-buts (voir Figure ci-dessous; gauche: données non-transformées, droite: données log transformées). En effet, la majorité des tirs (buts et non-buts) sont effectués à environ 10 pieds du filet. Au-delà de 10 pieds, le nombre de non-buts diminue et reste relativement stable entre 20 et 60 pieds pour diminuer de manière drastique au-delà de 60 pieds du filet. Le nombre de buts semble diminué de manière constante entre 20 et 60 pieds. au-delà de 60 pieds, le nombre de buts semble suivre la même tendance que le nombre de non-buts. Nous pouvons également conclure qu'il y a beaucoup moins de buts que de non-buts.

<p align="center">
      <img src="../assets/images/milestone2/shots_goals_distance.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/shots_goals_distance_log.png" width="550" height="425">
</p>

Le nombre de tirs selon l'angle n'est pas distribué normalement, autant pour les buts que les non-buts. Nous pouvons observer que la distribution des non-buts semble être tri-modale, avec un pic à environ -30 degrés, un pic à 0 degré et un pic à environ 30 degré. La distribution de part et d'autres du zéro semble assez symétrique, ce qui suggère que nous pourrions considérer la valeur absolue des angles. En d'autres mots, que le tireur soit à gauche ou à droite du gradien ne semble pas avoir d'incidence sur le nombre de tirs ainsi que sur le nombre de buts. La distribution des buts ressemble un peu plus à une distribution normale, bien qu'il y a une prévalence qu'il y a un nombre de buts plus important lorsque l'angle entre le tireur et le filet est proche de 0.

<p align="center">
      <img src="../assets/images/milestone2/shots_goals_angle.png" align="left" width="550" height="425">
      <img src="../assets/images/milestone2/shots_goals_angle_log.png" width="550" height="425">
</p>

Nous pouvons tirer les mêmes conclusions globales que précédemment en regardant l'histogramme 2D ci-dessous. Par contre, il est à noter que les tirs ne sont pas séparés en buts et  non-buts dans cette figure. L'histogramme 2D nous permet également de voir qu'à plus de 40 pieds du filet, l'angle de tir décroit de manière exponentielle jusqu'à environ 25 degrés. 

<img src="../assets/images/milestone2/hist_2d_distance_angle.png">


### Question 2

Le taux de buts décroit à mesure que la distance augmente entre le tir et le filet augmenter (Figure de gauche). Ce taux est plus grand lorsque l'angle entre le tir et le filet est environ entre 5 et 10 degrés. Par la suite, le taux de buts diminue plus l'angle augmente.

<p align="center">
    <img src="../assets/images/milestone2/goal_rate_distance.png" align="left" height="400" width="590">
    <img src="../assets/images/milestone2/goal_rate_angle.png" height="400" width="590">
</p>

### Question 3

Nous pouvons observer qu'il y a un plus grand nombre de buts marqués aux alentours de 10 pieds lorsque le filet n'est pas vide. Lorsque la distance entre le tir et le filet dépasse les 10 pieds, le nombre de buts marqués diminue presque exponentiellement en fonction de la distance. Lorsque le filet est vide, le nombre de buts ne semble pas dépendre de la distance entre le tir et le filet.

<p align="center">
      <img src="../assets/images/milestone2/goals_distance_empty_goal.png" align="left" width="550" 
height="425">
      <img src="../assets/images/milestone2/goals_distance_empty_goal_log.png" width="550" height="425">
</p>


## Modèles de base

### Question 1

Le premier modèle demandé a été entraîné sur 80% des données et la précision (*accuracy*) a été calculée sur le 20% des données restantes. Nous avons obtenu une précision de 90.55 %. Par contre, si l'on 

La métrique de précision (*accuracy*) ne tient malheureusement pas compte des prédictions faites par classe, uniquement des prédictions sur l'ensemble des classes. Ceci pose un problème lorsque nous avons des classes débalancées. En effet, si l'on regarde la proportion de chaque classe dans nos données, nous pouvons observer que 90.55% de nos observations appartiennent à la classe 0 (i.e., non-but). En regardant la matrice de confusion, nous pouvons bel et bien voir que ce modèle prédit systématiquement la classe majoratoire.
```
```

Il est donc important de considérer des métriques différentes pour évaluer de manière adéquate nos modèles.

### Question 2

Le code pour produire les graphiques demandés pour la question 2 se trouve dans le script `Plots.py`(https://github.com/mathieupelo/ift6758-A08/blob/main/scripts/Plots.py). Ce code a été réutilisé dans les sections suivantes.

### Question 3

TODO: Insérer les 4 figures
TODO: Discuter de l'interprétation

### Question 4

TODO: Insérer liens vers comet.ml des 3 modèles

## Ingénierie des caractéristiques II

Ci-dessous se trouve la liste des caractéristiques créées:

- `gameId`: numéro d'identification unique pour chaque match de hockey
- `evt_idx`: Identifiant unique pour chaque action (tir ou but) dans un match
- `prd`: indique la période du match (1, 2, 3, prolongation, tirs au but)
- `prdTime`: temps écoulé dans la période courante, format minutes:secondes
- `team`: nom de l'équipe qui effectue l'action
- `goalFlag`: indique si le tir a résulté en un but
- `shotCategory`: catégorie ou type de tir effectué
- `coord_x`: coordonnée horizontale de l'action sur la glace
- `coord_y`: coordonnée verticale de l'action sur la glace
- `shotBy`: nom du joueur qui a effectué le tir
- `goalieName`: Nom du gardien de but au moment de l'action
- `noGoalie`: Indique si le but était vide lors du tir
- `teamStrength`: force numérique de l'équipe sur la glace (ex: 5 contre 5)
- `visitorTeam`: nom de l'équipe visiteuse
- `hostTeam`: nom de l'équipe hôte
- `homeRinkSide`: côté de la patinoire de l'équipe hôte en début de match
- `awayRinkSide`: côté de la patinoire de l'équipe visiteuse en début de match
- `last_event_type`: type de la dernière action enregistrée
- `last_event_x`: coordonnée horizontale de la dernière action
- `last_event_y`: coordonnée verticale de la dernière action
- `time_since_last_event`: temps écoulé depuis la dernière action (en secondes)
- `distance_from_last_event`: distance parcourue depuis la dernière action
- `game_seconds`: temps total écoulé dans le match (en secondes)
- `shot_distance`: distance du tir par rapport au but
- `shot_angle`: angle du tir par rapport au but
- `rebond`: indique si le tir était un rebond d'un tir précédent
- `changement_angle_tir`: changement d'angle entre ce tir et le tir précédent
- `vitesse`: vitesse du tir (distance depuis l'évènement précédent / temps depuis l'évènement précédent)

Le calcul des variables créées dans cette partie est montré ci-dessous pour un tir i donné:

```
time_since_last_event = ???

distance_from_last_event[i] = np.sqrt((coord_x[i] - coord_x[i-1])**2 + (coord_y[i] - coord_y[i-1])**2)

game_seconds = prdTime_minutes*60 + prdTime_secondes; 
où prdTime_minutes est la portion exprimée en minutes de prdTime et prdTime_secondes, la portion en secondes

changement_angle_tir[i] = shot_angle[i] + shot_angle[i-1]

vitesse[i] = distance_from_last_event[i] / time_since_last_event[i]
```

TODO: Insérer lien comet.ml

## Modèles avancés

### Question 1

TODO: Insérer les 4 figures
TODO: discuter de la configuration train/validation
TODO: Insérer lien vers comet.ml

### Question 2

L'optimisation d'hyperparamètres a été effectué en utilisant une approche de recherche par grille (i.e., [*GridSearch*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)). Pour ce modèle, nous avons considéré les trois hyperparamètres suivants:

- `n_estimator`: nombre total d'arbres 
- `max_depth`: profondeur maximale de chaque arbre
- `learning_rate`: taux d'apprentissage utilisé pour mettre à jour la contribution des nouveaux arbres au modèle

La grille de recherche pour ces paramètres a été définie avec les valeurs suivantes:
- `n_estimator`: [50, 100, 200]
- `max_depth`: [3, 5, 7]
- `learning_rate`: [0.01, 0.1, 0.2]

Pour la validation-croisée, un Kfold avec k=5 a été effectué, ce qui signifie que 135 (3x3x3x5) combinaisons possibles d'hyperparamètres ont été testées. La meilleure solution a été trouvée avec les valeurs suivantes:
- `n_estimators` = 50
- `max_depth` = 5
- `learning_rate` = 0.1

Le modèle avec les hyperparamètres utilisés a mené à une augmentation du score ROC d'environ 0.0026 (0.5842 pour le modèle non-optimisé vs 0.5868 pour le modèle optimisé), ce qui constitue qu'une faible amélioration comparativement aux résultats précedemment obtenus. Par contre, la méthode de recherche par grille ne couvre pas de manière efficace l'espace des valeurs d'hyperparamètres possibles. Cette méthode pourrait donc manquer la solution optimale des valeurs d'hyperparamètres. Il serait donc plus pertinent de procéder à l'optimisation d'hyperparamètres avec la méthode de l'hypercube latin aléatoire, puisque cette dernière permet de couvrir de manière plus efficace la distribution d'hyperparamètres. Il serait également possible de considérer d'autres hyperparamètres à optimiser tels que le nombre maximum de feuille (`max_leaves`), le terme de régularisation (p.ex. `reg_alpha`), le poids minimal de l'enfant (`min_child_weight`), etc.

TODO: Insérer figure pour justifier le choix des hyperparamètres
TODO: Insérer les 4 figures
TODO: Insérer lien comet.ml

### Question 3

TODO: Discuter stratégies de sélection de features
TODO: Insérer des figures pour justifier le choix
TODO: Insérer les 4 figiures
TODO: Insérer le lien comet.ml

## Faites de votre mieux !

Pour cette partie, nous avons tester trois différents modèles pour prédire les buts espérés: Forêt aléatoire, Machine à vecteurs de support, Réseau de neurones. Les particularités de chaque modèle sont décrites ci-dessous:

### Caractéristiques des modèles

**Pré-traitement des caractéristiques**

Avant d'entraîner les modèles sélectionnés (voir section *Algorithmes de classification*), nous avons effectué un prétraitement sur nos caractéristiques. Premièrement, la variable *teamStrength* a été exclus de notre ensemble des caractéristiques puisqu'elle comprenait plus de 50% d'observations manquantes. Les lignes comptenant des valeurs manquantes ont été supprimées (i.e., 227033), menant a un total de 158043 observations sur lesquelles nos modèles ont été entraînés. Les variables *gameId*, *evt_idx*, *team*, *shotBy*, *goalieName*, *visitorTeam*, *hostTeam*, *homeRinkSide*, *awayRinkSide* n'ont pas été considérées dans l'ensemble des caractéristiques dans le but d'augmenter la robustesse et la stabilité de nos modèles. En effet, puisque plusieurs joueurs intègrent ou quittent la LNH à chaque saison, il est préférable de ne pas considérer les variables *shotBy* et *goalieName* pour prédire les buts espérés au travers différentes saisons. Le nom des équipes n'a pas été pris en compte puisque d'une saison à l'autre la performance des équipe peut grandement varier. Dans ce cas, le modèle pourrait capitaliser sur la performance des équipes pour les saisons vues durant l'entrainement pour faire ses prédictions, ce qui effecterait la généralisabilité du modèles à de nouvelles données. Finalement, le côté de la patinoire n'a pas été inclus puisque, selon nos connaissances, cette variable ne devrait pas influencer la variable cible. La variable *prdTime* a été enlevée puisqu'elle est redondante avec les variables *prd* et *game_seconds* qui ont été incluses dans l'ensemble de caractéristiques.

Ensuite, les variables *shotCategory* et *last_event_type* catégorielles ont été encodées avec la technique de *Hot-One-Encoding* selon l'implémentation de la librairie pandas (voir [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)). Les variables continues *coord_x*, *coord_y*, *last_event_x*, *last_event_y*, *time_since_last_event*, *distance_from_last_event*, *game_seconds*, *shot_distance*, *shot_angle*, *changement_angle_tir* et *vitesse* ont été standardisées grâce à la fonction [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de scikit-learn. Un encodage binaire a été effectué sur les variables *noGoalie* et *rebond* grâce à la fonction [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) de scikit-learn. La variable cible *goalFlag* a également été binarisée. Le prétraitement des données est réalisé par la fonction `preprocessing` se trouvant dans le script [feature_engineering.py](https://github.com/mathieupelo/ift6758-A08/blob/main/scripts/feature_engineering.py).

**Caractéristiques finales**

Les modèles testés dans cette section ont été entraînés sur des données de dimensions 158043 observations x 30 caractéristiques. Les caractéristiques incluent: 

- Période de jeu: *prd* (variable ordinale)
- Coordonnées en x du tir: *coord_x* (variable continue standardisée)
- Coordonnées en y du tir: *coord_y* (variable continue standardisée)
- Filet désert: *noGoalie* (variable binaire; 1: si filet désert, autrement 0)
- Coordonnées en x de l'évènement précédent: *last_event_x* (variable continue standardisée)
- Coordonnées en y de l'évènement précédent: *last_event_y* (variable continue standardisée)
- Temps depuis le dernier évènement: *time_since_last_event* (variable continue standardisée)
- Distance du dernier évènement: *distance_from_last_event* (variable continue standardisée)
- Temps de jeu: *game_seconds* (variable continue standardisée)
- Distance de tir: *shot_distance* (variable continue standardisée)
- Angle de tir: *shot_angle* (variable continue standardisée)
- Rebond du tir: *rebond* (variable binaire; 1: si le tir provient d'un rebond, autrement 0)
- Changement d'angle de tir: *changement_angle_tir* (variable continue standardisée)
- Vitesse de tir: *vitesse* (variable continue standardisée)
- Type de tir: *shotCategory* encodée à chaud en 7 variables binaires (*shotCategory_Backhand*, *shotCategory_Deflected*, *shotCategory_Slap Shot*, *shotCategory_Snap Shot*, *shotCategory_Tip-In*, *shotCategory_Wrap-around*, *shotCategory_Wrist Shot*)
- Type de l'évènement précédent: *last_event_type* encodée à chaud en 9 variables binaires (*last_event_type_BLOCKED_SHOT*, *last_event_type_FACEOFF*, *last_event_type_GIVEAWAY*, *last_event_type_GOAL*, *last_event_type_HIT*, *last_event_type_MISSED_SHOT*, *last_event_type_PENALTY*, *last_event_type_SHOT*, *last_event_type_TAKEAWAY*)

### Algorithmes de classification

**Forêt aléatoire**

L'algorithme de forêt aléatoire a été inclus dans les modèles testés en raison de son efficacité démontrée sur les données tabulaires ([Grinztajn et al., 2022](https://
proceedings.neurips.cc/paper_files/paper/2022/file/0378c7692da36807bdec87ab043cdadc-Paper-Datasets_and_Benchmarks.pdf)). 

**Machine à vecteurs de support (SVM)**

**Réseau de neurones**

Un réseau de neurones a été entraîné et évalué à partir des fonctions fournies dans la librairie [`pytorch-tabular`](https://pytorch-tabular.readthedocs.io/en/latest/). Cette librairie a été choisie pour tenir compte de la nature de nos données; i.e. données tabulaires. Le script développé a été adapté d'un [tutoriel](https://pytorch-tabular.readthedocs.io/en/latest/tutorials/06-Imbalanced%20Classification/) disponible sur la documentation de `pytorch-tabular`.

### Performance des modèles

TODO: Discuter des différentes techniques utilisées
TODO: Insérer les 4 figures

**Forêt aléatoire**

**Machine à vecteurs de support**

**Réseau de neurones**

**Comparaisons des modèles**

## Évaluer sur l'ensemble de test

### Question 1

TODO: Insérer les 4 figures.
TODO: Discuter la performance des modèles

### Question 2

TODO: Insérer les 4 figures
TODO: Discuter la performance des modèles